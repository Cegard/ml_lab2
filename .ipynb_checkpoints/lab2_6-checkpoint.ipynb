{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAM Detection - The Naive Bayes Algorithm in Python with Scikit-Learn \n",
    "D. Shahrokhian\n",
    "https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuck all you hoes\\nGet a grip motherfucker.\\nY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As I grab the glock, put it to your headpiece\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't wanna live no mo'\\nSometimes I hear de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To all the ladies in the place with style and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nineteen-seventy somethin', nigga I don't swea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Another day in the ghetto \\nOne look outside I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Live from Bedford-Stuyverson, the livest one\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Uh, uh, uh, c'mon\\nHah, sicker than your avera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Uhh, uhhh\\nB.I.G., P-O, P-P-A\\nNo info, for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uhh, it's the ten crack commandments\\nWhat, uh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Commission\\nUncle Paulie, Big Ditti\\nCaesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Relax and take notes, while I take tokes of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Good evenin ladies and gentlemen\\nHow's everyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Who shot ya?\\nSeperate the weak from the ob-so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>When I die, fuck it I wanna go to hell\\nCause ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>When the lala hits ya lyrics just splits ya\\nH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    1\n",
       "0   Fuck all you hoes\\nGet a grip motherfucker.\\nY...\n",
       "1   As I grab the glock, put it to your headpiece\\...\n",
       "2   I don't wanna live no mo'\\nSometimes I hear de...\n",
       "3   To all the ladies in the place with style and ...\n",
       "4   Nineteen-seventy somethin', nigga I don't swea...\n",
       "5   Another day in the ghetto \\nOne look outside I...\n",
       "6   Live from Bedford-Stuyverson, the livest one\\n...\n",
       "7   Uh, uh, uh, c'mon\\nHah, sicker than your avera...\n",
       "8   Uhh, uhhh\\nB.I.G., P-O, P-P-A\\nNo info, for th...\n",
       "9   Uhh, it's the ten crack commandments\\nWhat, uh...\n",
       "10  The Commission\\nUncle Paulie, Big Ditti\\nCaesa...\n",
       "11  Relax and take notes, while I take tokes of th...\n",
       "12  Good evenin ladies and gentlemen\\nHow's everyb...\n",
       "13  Who shot ya?\\nSeperate the weak from the ob-so...\n",
       "14  When I die, fuck it I wanna go to hell\\nCause ...\n",
       "15  When the lala hits ya lyrics just splits ya\\nH..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "biggie_df = pd.read_csv('data/biggie_lyrics.csv', usecols=[1], encoding='latin-1', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  go until jurong point crazy available only in ...\n",
       "1      0                            ok lar joking wif u oni\n",
       "2      1  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3      0        u dun say so early hor u c already then say\n",
       "4      0  nah i dont think he goes to usf he lives aroun..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n",
    "df['message'] = df.message.map(lambda x: x.lower())\n",
    "df['message'] = df.message.str.replace('[^\\w\\s]', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/ Natural Language Toolkit\n",
    "# Punkt Sentence Tokenizer https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "df['message'] = df['message'].apply(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.stem.html\n",
    "#https://tartarus.org/martin/PorterStemmer/\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the list of words into space-separated strings\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9074)\t1\n",
      "  (0, 1195)\t1\n",
      "  (0, 3896)\t1\n",
      "  (0, 8384)\t1\n",
      "  (0, 2248)\t1\n",
      "  (0, 1907)\t1\n",
      "  (0, 3065)\t1\n",
      "  (0, 4917)\t1\n",
      "  (0, 9322)\t1\n",
      "  (0, 3936)\t1\n",
      "  (0, 5754)\t1\n",
      "  (0, 1909)\t1\n",
      "  (0, 4463)\t1\n",
      "  (0, 6120)\t1\n",
      "  (0, 1433)\t1\n",
      "  (0, 2532)\t1\n",
      "  (0, 6529)\t1\n",
      "  (0, 4754)\t1\n",
      "  (0, 8812)\t1\n",
      "  (0, 3839)\t1\n",
      "  (1, 6114)\t1\n",
      "  (1, 8728)\t1\n",
      "  (1, 9214)\t1\n",
      "  (1, 4722)\t1\n",
      "  (1, 4956)\t1\n",
      "  :\t:\n",
      "  (5570, 3145)\t1\n",
      "  (5570, 7738)\t1\n",
      "  (5570, 1937)\t1\n",
      "  (5570, 8855)\t1\n",
      "  (5570, 2829)\t1\n",
      "  (5570, 5856)\t1\n",
      "  (5570, 9124)\t1\n",
      "  (5570, 1575)\t1\n",
      "  (5570, 8361)\t1\n",
      "  (5570, 4603)\t1\n",
      "  (5570, 3570)\t1\n",
      "  (5570, 7727)\t1\n",
      "  (5570, 5069)\t1\n",
      "  (5570, 4404)\t1\n",
      "  (5570, 1211)\t1\n",
      "  (5570, 4095)\t1\n",
      "  (5570, 4387)\t1\n",
      "  (5570, 8509)\t1\n",
      "  (5570, 3622)\t1\n",
      "  (5570, 4463)\t1\n",
      "  (5571, 7151)\t1\n",
      "  (5571, 8658)\t1\n",
      "  (5571, 5767)\t1\n",
      "  (5571, 4624)\t2\n",
      "  (5571, 8509)\t1\n"
     ]
    }
   ],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "# to allow one letter words count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "counts = count_vect.fit_transform(df['message'])  \n",
    "print counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 9579)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#transformer = TfidfTransformer().fit(counts)\n",
    "\n",
    "#counts = transformer.transform(counts)\n",
    "#print counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802867383512545\n",
      "[[477   5]\n",
      " [  6  70]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69) \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "print(np.mean(predicted == y_test))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n",
      "[[478  11]\n",
      " [  7  62]]\n",
      "0.967741935483871\n",
      "[[477  12]\n",
      " [  6  63]]\n",
      "0.9731182795698925\n",
      "[[463   8]\n",
      " [  7  80]]\n",
      "0.9838709677419355\n",
      "[[481   5]\n",
      " [  4  68]]\n",
      "0.9802867383512545\n",
      "[[462   6]\n",
      " [  5  85]]\n",
      "0.9731182795698925\n",
      "[[476   8]\n",
      " [  7  67]]\n",
      "0.9713261648745519\n",
      "[[487  10]\n",
      " [  6  55]]\n",
      "0.9767025089605734\n",
      "[[474  10]\n",
      " [  3  71]]\n",
      "0.9838709677419355\n",
      "[[483   6]\n",
      " [  3  66]]\n",
      "0.9874551971326165\n",
      "[[470   3]\n",
      " [  4  81]]\n",
      "average perfromance\n",
      "0.9765232974910395\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9739910313901345\n",
      "[[945  15]\n",
      " [ 14 141]]\n",
      "0.9757847533632287\n",
      "[[949  16]\n",
      " [ 11 139]]\n",
      "0.9766816143497757\n",
      "[[959  15]\n",
      " [ 11 130]]\n",
      "0.979372197309417\n",
      "[[952  13]\n",
      " [ 10 140]]\n",
      "0.979372197309417\n",
      "[[951  14]\n",
      " [  9 141]]\n",
      "0.97847533632287\n",
      "[[958  18]\n",
      " [  6 133]]\n",
      "0.9713004484304932\n",
      "[[945  16]\n",
      " [ 16 138]]\n",
      "0.9847533632286996\n",
      "[[961   9]\n",
      " [  8 137]]\n",
      "0.9820627802690582\n",
      "[[948  14]\n",
      " [  6 147]]\n",
      "0.9838565022421525\n",
      "[[977   6]\n",
      " [ 12 120]]\n",
      "average perfromance\n",
      "0.9785650224215248\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.2) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788226848528356\n",
      "[[2381   19]\n",
      " [  40  346]]\n",
      "0.9752333094041636\n",
      "[[2381   22]\n",
      " [  47  336]]\n",
      "0.9773869346733668\n",
      "[[2385   26]\n",
      " [  37  338]]\n",
      "0.9777458722182341\n",
      "[[2380   25]\n",
      " [  37  344]]\n",
      "0.9755922469490309\n",
      "[[2376   36]\n",
      " [  32  342]]\n",
      "0.9748743718592965\n",
      "[[2373   35]\n",
      " [  35  343]]\n",
      "0.9773869346733668\n",
      "[[2395   30]\n",
      " [  33  328]]\n",
      "0.9759511844938981\n",
      "[[2381   28]\n",
      " [  39  338]]\n",
      "0.9777458722182341\n",
      "[[2386   25]\n",
      " [  37  338]]\n",
      "0.9773869346733668\n",
      "[[2373   34]\n",
      " [  29  350]]\n",
      "average perfromance\n",
      "0.9768126346015794\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.5) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
